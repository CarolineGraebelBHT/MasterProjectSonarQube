{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48afd397-593c-4d38-a087-0a58df251d54",
   "metadata": {},
   "source": [
    "# Logistic Regression for each tag\n",
    "Logistic Regression is one of the state of the art models for binary classification. The goal is to model each tag through its own model. To ensure the best prediction, F1-Score is optimised for balancing recall and precision. Accuracy is not suitable, since some tags are very unbalanced. The models are optimised with cross-validated gridsearch. This modelling approach doesn't account for the time series aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ac4640-7f6f-4da5-93b8-b4eada92e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import make_scorer\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f2e6d6-e01f-49cf-97ef-e5bba7607231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>SQ_ANALYSIS_DATE</th>\n",
       "      <th>CLASSES</th>\n",
       "      <th>FILES</th>\n",
       "      <th>LINES</th>\n",
       "      <th>NCLOC</th>\n",
       "      <th>PACKAGE</th>\n",
       "      <th>STATEMENTS</th>\n",
       "      <th>FUNCTIONS</th>\n",
       "      <th>COMMENT_LINES</th>\n",
       "      <th>...</th>\n",
       "      <th>FUNCTION_COMPLEXITY</th>\n",
       "      <th>COGNITIVE_COMPLEXITY</th>\n",
       "      <th>LINES_TO_COVER</th>\n",
       "      <th>UNCOVERED_LINES</th>\n",
       "      <th>DUPLICATED_LINES</th>\n",
       "      <th>DUPLICATED_BLOCKS</th>\n",
       "      <th>DUPLICATED_FILES</th>\n",
       "      <th>COMMENT_LINES_DENSITY</th>\n",
       "      <th>DUPLICATED_LINES_DENSITY</th>\n",
       "      <th>TAGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-03-03 00:37:22</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>1088490.0</td>\n",
       "      <td>743742.0</td>\n",
       "      <td>387</td>\n",
       "      <td>358319.0</td>\n",
       "      <td>62459.0</td>\n",
       "      <td>76113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>121074.0</td>\n",
       "      <td>437602.0</td>\n",
       "      <td>437602.0</td>\n",
       "      <td>140806</td>\n",
       "      <td>7917</td>\n",
       "      <td>813</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>brain-overload, unused, antipattern, pitfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13699</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-03-02 18:18:35</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>1088466.0</td>\n",
       "      <td>743721.0</td>\n",
       "      <td>387</td>\n",
       "      <td>358306.0</td>\n",
       "      <td>62458.0</td>\n",
       "      <td>76112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>121067.0</td>\n",
       "      <td>437585.0</td>\n",
       "      <td>437585.0</td>\n",
       "      <td>140806</td>\n",
       "      <td>7917</td>\n",
       "      <td>813</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>error-handling, design, unused, suspicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13700</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 23:08:33</td>\n",
       "      <td>8468.0</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>1087272.0</td>\n",
       "      <td>742901.0</td>\n",
       "      <td>387</td>\n",
       "      <td>357917.0</td>\n",
       "      <td>62390.0</td>\n",
       "      <td>76071.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>120954.0</td>\n",
       "      <td>437096.0</td>\n",
       "      <td>437096.0</td>\n",
       "      <td>140709</td>\n",
       "      <td>7913</td>\n",
       "      <td>810</td>\n",
       "      <td>9.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>convention, pitfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13701</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 21:30:05</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>1071783.0</td>\n",
       "      <td>731599.0</td>\n",
       "      <td>364</td>\n",
       "      <td>352969.0</td>\n",
       "      <td>61412.0</td>\n",
       "      <td>75080.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>119218.0</td>\n",
       "      <td>431125.0</td>\n",
       "      <td>431125.0</td>\n",
       "      <td>139347</td>\n",
       "      <td>7774</td>\n",
       "      <td>791</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>pitfall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13702</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 21:09:45</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>1071783.0</td>\n",
       "      <td>731599.0</td>\n",
       "      <td>364</td>\n",
       "      <td>352969.0</td>\n",
       "      <td>61412.0</td>\n",
       "      <td>75080.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>119218.0</td>\n",
       "      <td>431125.0</td>\n",
       "      <td>431125.0</td>\n",
       "      <td>139347</td>\n",
       "      <td>7774</td>\n",
       "      <td>791</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>error-handling, clumsy, design, suspicious, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15549</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-18 17:37:59</td>\n",
       "      <td>664.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>72263.0</td>\n",
       "      <td>51707.0</td>\n",
       "      <td>33</td>\n",
       "      <td>28559.0</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>33041.0</td>\n",
       "      <td>33041.0</td>\n",
       "      <td>17659</td>\n",
       "      <td>1224</td>\n",
       "      <td>75</td>\n",
       "      <td>5.9</td>\n",
       "      <td>24.4</td>\n",
       "      <td>error-handling, clumsy, brain-overload, bad-pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15550</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-18 00:09:17</td>\n",
       "      <td>661.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>71629.0</td>\n",
       "      <td>51241.0</td>\n",
       "      <td>33</td>\n",
       "      <td>28335.0</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>11061.0</td>\n",
       "      <td>32889.0</td>\n",
       "      <td>32889.0</td>\n",
       "      <td>17789</td>\n",
       "      <td>1228</td>\n",
       "      <td>74</td>\n",
       "      <td>5.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>error-handling, clumsy, brain-overload, design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15551</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-17 20:13:00</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67865.0</td>\n",
       "      <td>48976.0</td>\n",
       "      <td>29</td>\n",
       "      <td>27145.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>10701.0</td>\n",
       "      <td>31505.0</td>\n",
       "      <td>31505.0</td>\n",
       "      <td>16785</td>\n",
       "      <td>1208</td>\n",
       "      <td>66</td>\n",
       "      <td>5.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>convention, design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15552</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-17 00:28:22</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67754.0</td>\n",
       "      <td>48873.0</td>\n",
       "      <td>29</td>\n",
       "      <td>27078.0</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>10691.0</td>\n",
       "      <td>31428.0</td>\n",
       "      <td>31428.0</td>\n",
       "      <td>16790</td>\n",
       "      <td>1208</td>\n",
       "      <td>66</td>\n",
       "      <td>5.8</td>\n",
       "      <td>24.8</td>\n",
       "      <td>brain-overload, clumsy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15553</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-02 23:58:59</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67469.0</td>\n",
       "      <td>48651.0</td>\n",
       "      <td>29</td>\n",
       "      <td>26933.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>10623.0</td>\n",
       "      <td>31250.0</td>\n",
       "      <td>31250.0</td>\n",
       "      <td>16728</td>\n",
       "      <td>1204</td>\n",
       "      <td>66</td>\n",
       "      <td>5.7</td>\n",
       "      <td>24.8</td>\n",
       "      <td>error-handling, clumsy, brain-overload, design...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROJECT_ID     SQ_ANALYSIS_DATE  CLASSES   FILES      LINES     NCLOC  \\\n",
       "13698       hive  2015-03-03 00:37:22   8477.0  3882.0  1088490.0  743742.0   \n",
       "13699       hive  2015-03-02 18:18:35   8477.0  3882.0  1088466.0  743721.0   \n",
       "13700       hive  2015-02-27 23:08:33   8468.0  3872.0  1087272.0  742901.0   \n",
       "13701       hive  2015-02-27 21:30:05   8327.0  3789.0  1071783.0  731599.0   \n",
       "13702       hive  2015-02-27 21:09:45   8327.0  3789.0  1071783.0  731599.0   \n",
       "...          ...                  ...      ...     ...        ...       ...   \n",
       "15549       hive  2008-09-18 17:37:59    664.0   399.0    72263.0   51707.0   \n",
       "15550       hive  2008-09-18 00:09:17    661.0   397.0    71629.0   51241.0   \n",
       "15551       hive  2008-09-17 20:13:00    613.0   358.0    67865.0   48976.0   \n",
       "15552       hive  2008-09-17 00:28:22    613.0   358.0    67754.0   48873.0   \n",
       "15553       hive  2008-09-02 23:58:59    613.0   358.0    67469.0   48651.0   \n",
       "\n",
       "       PACKAGE  STATEMENTS  FUNCTIONS  COMMENT_LINES  ...  \\\n",
       "13698      387    358319.0    62459.0        76113.0  ...   \n",
       "13699      387    358306.0    62458.0        76112.0  ...   \n",
       "13700      387    357917.0    62390.0        76071.0  ...   \n",
       "13701      364    352969.0    61412.0        75080.0  ...   \n",
       "13702      364    352969.0    61412.0        75080.0  ...   \n",
       "...        ...         ...        ...            ...  ...   \n",
       "15549       33     28559.0     4592.0         3235.0  ...   \n",
       "15550       33     28335.0     4538.0         3215.0  ...   \n",
       "15551       29     27145.0     4346.0         2985.0  ...   \n",
       "15552       29     27078.0     4340.0         2983.0  ...   \n",
       "15553       29     26933.0     4334.0         2958.0  ...   \n",
       "\n",
       "       FUNCTION_COMPLEXITY  COGNITIVE_COMPLEXITY  LINES_TO_COVER  \\\n",
       "13698                  2.3              121074.0        437602.0   \n",
       "13699                  2.3              121067.0        437585.0   \n",
       "13700                  2.3              120954.0        437096.0   \n",
       "13701                  2.3              119218.0        431125.0   \n",
       "13702                  2.3              119218.0        431125.0   \n",
       "...                    ...                   ...             ...   \n",
       "15549                  2.6               11206.0         33041.0   \n",
       "15550                  2.6               11061.0         32889.0   \n",
       "15551                  2.6               10701.0         31505.0   \n",
       "15552                  2.6               10691.0         31428.0   \n",
       "15553                  2.6               10623.0         31250.0   \n",
       "\n",
       "       UNCOVERED_LINES  DUPLICATED_LINES  DUPLICATED_BLOCKS  DUPLICATED_FILES  \\\n",
       "13698         437602.0            140806               7917               813   \n",
       "13699         437585.0            140806               7917               813   \n",
       "13700         437096.0            140709               7913               810   \n",
       "13701         431125.0            139347               7774               791   \n",
       "13702         431125.0            139347               7774               791   \n",
       "...                ...               ...                ...               ...   \n",
       "15549          33041.0             17659               1224                75   \n",
       "15550          32889.0             17789               1228                74   \n",
       "15551          31505.0             16785               1208                66   \n",
       "15552          31428.0             16790               1208                66   \n",
       "15553          31250.0             16728               1204                66   \n",
       "\n",
       "       COMMENT_LINES_DENSITY  DUPLICATED_LINES_DENSITY  \\\n",
       "13698                    9.3                      12.9   \n",
       "13699                    9.3                      12.9   \n",
       "13700                    9.3                      12.9   \n",
       "13701                    9.3                      13.0   \n",
       "13702                    9.3                      13.0   \n",
       "...                      ...                       ...   \n",
       "15549                    5.9                      24.4   \n",
       "15550                    5.9                      24.8   \n",
       "15551                    5.7                      24.7   \n",
       "15552                    5.8                      24.8   \n",
       "15553                    5.7                      24.8   \n",
       "\n",
       "                                                    TAGS  \n",
       "13698       brain-overload, unused, antipattern, pitfall  \n",
       "13699         error-handling, design, unused, suspicious  \n",
       "13700                                convention, pitfall  \n",
       "13701                                            pitfall  \n",
       "13702  error-handling, clumsy, design, suspicious, pi...  \n",
       "...                                                  ...  \n",
       "15549  error-handling, clumsy, brain-overload, bad-pr...  \n",
       "15550  error-handling, clumsy, brain-overload, design...  \n",
       "15551                                 convention, design  \n",
       "15552                             brain-overload, clumsy  \n",
       "15553  error-handling, clumsy, brain-overload, design...  \n",
       "\n",
       "[1856 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data import\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# construct path to the project data folder\n",
    "data_dir = os.path.join(current_dir, '..', '..', '..', 'Data','Sonar_Issues')\n",
    "\n",
    "model_save_dir = os.path.join(current_dir, '..', '..', '..', 'Data', 'Models', 'CodeSmellTags')\n",
    "\n",
    "# load SonarQube measure data\n",
    "df = pd.read_csv(os.path.join(data_dir, 'measures+tags.csv'), low_memory=False)\n",
    "df = df[df['PROJECT_ID'] == 'hive']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c614b55-ec5e-4a00-b8e3-da49c063873b",
   "metadata": {},
   "source": [
    "## Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2ff9ec-1af1-4a06-8a5d-129763791aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLB classes (order of one-hot columns): ['convention' 'brain-overload' 'unused' 'error-handling' 'bad-practice'\n",
      " 'pitfall' 'clumsy' 'suspicious' 'design' 'antipattern' 'redundant'\n",
      " 'confusing' 'performance' 'obsolete']\n",
      "Total number of possible labels: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROJECT_ID</th>\n",
       "      <th>SQ_ANALYSIS_DATE</th>\n",
       "      <th>CLASSES</th>\n",
       "      <th>FILES</th>\n",
       "      <th>LINES</th>\n",
       "      <th>NCLOC</th>\n",
       "      <th>PACKAGE</th>\n",
       "      <th>STATEMENTS</th>\n",
       "      <th>FUNCTIONS</th>\n",
       "      <th>COMMENT_LINES</th>\n",
       "      <th>...</th>\n",
       "      <th>bad-practice</th>\n",
       "      <th>pitfall</th>\n",
       "      <th>clumsy</th>\n",
       "      <th>suspicious</th>\n",
       "      <th>design</th>\n",
       "      <th>antipattern</th>\n",
       "      <th>redundant</th>\n",
       "      <th>confusing</th>\n",
       "      <th>performance</th>\n",
       "      <th>obsolete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-03-03 00:37:22</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>1088490.0</td>\n",
       "      <td>743742.0</td>\n",
       "      <td>387</td>\n",
       "      <td>358319.0</td>\n",
       "      <td>62459.0</td>\n",
       "      <td>76113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-03-02 18:18:35</td>\n",
       "      <td>8477.0</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>1088466.0</td>\n",
       "      <td>743721.0</td>\n",
       "      <td>387</td>\n",
       "      <td>358306.0</td>\n",
       "      <td>62458.0</td>\n",
       "      <td>76112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 23:08:33</td>\n",
       "      <td>8468.0</td>\n",
       "      <td>3872.0</td>\n",
       "      <td>1087272.0</td>\n",
       "      <td>742901.0</td>\n",
       "      <td>387</td>\n",
       "      <td>357917.0</td>\n",
       "      <td>62390.0</td>\n",
       "      <td>76071.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 21:30:05</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>1071783.0</td>\n",
       "      <td>731599.0</td>\n",
       "      <td>364</td>\n",
       "      <td>352969.0</td>\n",
       "      <td>61412.0</td>\n",
       "      <td>75080.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hive</td>\n",
       "      <td>2015-02-27 21:09:45</td>\n",
       "      <td>8327.0</td>\n",
       "      <td>3789.0</td>\n",
       "      <td>1071783.0</td>\n",
       "      <td>731599.0</td>\n",
       "      <td>364</td>\n",
       "      <td>352969.0</td>\n",
       "      <td>61412.0</td>\n",
       "      <td>75080.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-18 17:37:59</td>\n",
       "      <td>664.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>72263.0</td>\n",
       "      <td>51707.0</td>\n",
       "      <td>33</td>\n",
       "      <td>28559.0</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-18 00:09:17</td>\n",
       "      <td>661.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>71629.0</td>\n",
       "      <td>51241.0</td>\n",
       "      <td>33</td>\n",
       "      <td>28335.0</td>\n",
       "      <td>4538.0</td>\n",
       "      <td>3215.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-17 20:13:00</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67865.0</td>\n",
       "      <td>48976.0</td>\n",
       "      <td>29</td>\n",
       "      <td>27145.0</td>\n",
       "      <td>4346.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-17 00:28:22</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67754.0</td>\n",
       "      <td>48873.0</td>\n",
       "      <td>29</td>\n",
       "      <td>27078.0</td>\n",
       "      <td>4340.0</td>\n",
       "      <td>2983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>hive</td>\n",
       "      <td>2008-09-02 23:58:59</td>\n",
       "      <td>613.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>67469.0</td>\n",
       "      <td>48651.0</td>\n",
       "      <td>29</td>\n",
       "      <td>26933.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PROJECT_ID     SQ_ANALYSIS_DATE  CLASSES   FILES      LINES     NCLOC  \\\n",
       "0          hive  2015-03-03 00:37:22   8477.0  3882.0  1088490.0  743742.0   \n",
       "1          hive  2015-03-02 18:18:35   8477.0  3882.0  1088466.0  743721.0   \n",
       "2          hive  2015-02-27 23:08:33   8468.0  3872.0  1087272.0  742901.0   \n",
       "3          hive  2015-02-27 21:30:05   8327.0  3789.0  1071783.0  731599.0   \n",
       "4          hive  2015-02-27 21:09:45   8327.0  3789.0  1071783.0  731599.0   \n",
       "...         ...                  ...      ...     ...        ...       ...   \n",
       "1851       hive  2008-09-18 17:37:59    664.0   399.0    72263.0   51707.0   \n",
       "1852       hive  2008-09-18 00:09:17    661.0   397.0    71629.0   51241.0   \n",
       "1853       hive  2008-09-17 20:13:00    613.0   358.0    67865.0   48976.0   \n",
       "1854       hive  2008-09-17 00:28:22    613.0   358.0    67754.0   48873.0   \n",
       "1855       hive  2008-09-02 23:58:59    613.0   358.0    67469.0   48651.0   \n",
       "\n",
       "      PACKAGE  STATEMENTS  FUNCTIONS  COMMENT_LINES  ...  bad-practice  \\\n",
       "0         387    358319.0    62459.0        76113.0  ...             0   \n",
       "1         387    358306.0    62458.0        76112.0  ...             0   \n",
       "2         387    357917.0    62390.0        76071.0  ...             0   \n",
       "3         364    352969.0    61412.0        75080.0  ...             0   \n",
       "4         364    352969.0    61412.0        75080.0  ...             0   \n",
       "...       ...         ...        ...            ...  ...           ...   \n",
       "1851       33     28559.0     4592.0         3235.0  ...             1   \n",
       "1852       33     28335.0     4538.0         3215.0  ...             1   \n",
       "1853       29     27145.0     4346.0         2985.0  ...             0   \n",
       "1854       29     27078.0     4340.0         2983.0  ...             0   \n",
       "1855       29     26933.0     4334.0         2958.0  ...             1   \n",
       "\n",
       "      pitfall  clumsy  suspicious  design  antipattern  redundant  confusing  \\\n",
       "0           1       0           0       0            1          0          0   \n",
       "1           0       0           1       1            0          0          0   \n",
       "2           1       0           0       0            0          0          0   \n",
       "3           1       0           0       0            0          0          0   \n",
       "4           1       1           1       1            0          0          0   \n",
       "...       ...     ...         ...     ...          ...        ...        ...   \n",
       "1851        1       1           1       0            1          0          0   \n",
       "1852        1       1           1       1            1          0          0   \n",
       "1853        0       0           0       1            0          0          0   \n",
       "1854        0       1           0       0            0          0          0   \n",
       "1855        1       1           1       1            1          1          1   \n",
       "\n",
       "      performance  obsolete  \n",
       "0               0         0  \n",
       "1               0         0  \n",
       "2               0         0  \n",
       "3               0         0  \n",
       "4               0         0  \n",
       "...           ...       ...  \n",
       "1851            0         0  \n",
       "1852            1         1  \n",
       "1853            0         0  \n",
       "1854            0         0  \n",
       "1855            1         1  \n",
       "\n",
       "[1856 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tags = ['convention', 'brain-overload','unused','error-handling','bad-practice','pitfall',\n",
    "            'clumsy','suspicious','design','antipattern','redundant','confusing','performance','obsolete']\n",
    "\n",
    "# transform TAGS strings to lists\n",
    "df.loc[:, 'TAGS'] = df['TAGS'].str.split(',')\n",
    "# remove whitespaces\n",
    "df.loc[:, 'TAGS'] = df['TAGS'].apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "# save TAGS as raw_labels to be further processed\n",
    "raw_labels = df['TAGS']\n",
    "\n",
    "# initialise mlb with all tag categories\n",
    "mlb = MultiLabelBinarizer(classes=all_tags)\n",
    "# fit the mlb with the list of lists of raw labels\n",
    "Y_binarized = mlb.fit_transform(raw_labels)\n",
    "\n",
    "print(f\"MLB classes (order of one-hot columns): {mlb.classes_}\")\n",
    "num_classes = len(mlb.classes_)\n",
    "print(f\"Total number of possible labels: {num_classes}\")\n",
    "\n",
    "tags_df = pd.DataFrame(Y_binarized, columns=mlb.classes_)\n",
    "\n",
    "# create copy of original df with reset index so that the binarised labels get inserted correctly\n",
    "df_reset = df.reset_index(drop=True)\n",
    "\n",
    "# concatenate the new tags_df with  original df\n",
    "df_binary = pd.concat([df_reset.drop('TAGS', axis=1), tags_df], axis=1)\n",
    "df_binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f22b3f7-66f1-4bb4-854f-305960bb6b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROJECT_ID', 'SQ_ANALYSIS_DATE', 'CLASSES', 'FILES', 'LINES', 'NCLOC',\n",
       "       'PACKAGE', 'STATEMENTS', 'FUNCTIONS', 'COMMENT_LINES', 'COMPLEXITY',\n",
       "       'CLASS_COMPLEXITY', 'FUNCTION_COMPLEXITY', 'COGNITIVE_COMPLEXITY',\n",
       "       'LINES_TO_COVER', 'UNCOVERED_LINES', 'DUPLICATED_LINES',\n",
       "       'DUPLICATED_BLOCKS', 'DUPLICATED_FILES', 'COMMENT_LINES_DENSITY',\n",
       "       'DUPLICATED_LINES_DENSITY', 'convention', 'brain-overload', 'unused',\n",
       "       'error-handling', 'bad-practice', 'pitfall', 'clumsy', 'suspicious',\n",
       "       'design', 'antipattern', 'redundant', 'confusing', 'performance',\n",
       "       'obsolete'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1844766f-39f7-4da3-85bc-b0803ab63a75",
   "metadata": {},
   "source": [
    "## Scale predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e8ac7b-282c-48be-9495-a7958473b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale = ['CLASSES', 'FILES', 'LINES', 'NCLOC',\n",
    "       'PACKAGE', 'STATEMENTS', 'FUNCTIONS', 'COMMENT_LINES', 'COMPLEXITY',\n",
    "       'CLASS_COMPLEXITY', 'FUNCTION_COMPLEXITY', 'COGNITIVE_COMPLEXITY',\n",
    "       'LINES_TO_COVER', 'UNCOVERED_LINES', 'DUPLICATED_LINES',\n",
    "       'DUPLICATED_BLOCKS', 'DUPLICATED_FILES', 'COMMENT_LINES_DENSITY',\n",
    "       'DUPLICATED_LINES_DENSITY']\n",
    "scaler = StandardScaler()\n",
    "df_binary[columns_to_scale] = scaler.fit_transform(df_binary[columns_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba3924-64d8-4920-8135-b7556b844a62",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59681693-013f-4179-a126-a6595ba98dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X = df_binary.drop(columns = ['PROJECT_ID', 'SQ_ANALYSIS_DATE', 'convention', 'brain-overload', 'unused',\n",
    "       'error-handling', 'bad-practice', 'pitfall', 'clumsy', 'suspicious',\n",
    "       'design', 'antipattern', 'redundant', 'confusing', 'performance',\n",
    "       'obsolete'])\n",
    "y = df_binary[['convention', 'brain-overload', 'unused',\n",
    "       'error-handling', 'bad-practice', 'pitfall', 'clumsy', 'suspicious',\n",
    "       'design', 'antipattern', 'redundant', 'confusing', 'performance',\n",
    "       'obsolete']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df1769-7bd0-4aa5-9f70-79fd67f0cb9c",
   "metadata": {},
   "source": [
    "## Prepare lists for saving model metrics\n",
    "To make comparability of the multiple models easier, the test metrics of each model are saved into a list and exported into a csv for further analysis at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b9717b-bae5-45f9-aa21-84b1153d67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_list = []\n",
    "acc_list = []\n",
    "prec_list = []\n",
    "recall_list = []\n",
    "f1_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bae8a4-8924-4a01-9402-5698ce87c686",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a2796-b2b4-4667-acee-f45e392b8d36",
   "metadata": {},
   "source": [
    "### Convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c000084-faa1-4a45-895b-93380fe7f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Logistic Regression Model Evaluation for Tag: convention\n",
      "Accuracy: 0.5456989247311828\n",
      "ROC-AUC: 0.5888019701579024\n",
      "Precision: 0.5212765957446809\n",
      "Recall: 0.5536723163841808\n",
      "F1 Score: 0.5369863013698629\n"
     ]
    }
   ],
   "source": [
    "tag = 'convention'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "def custom_f1_with_threshold_tuning(y_true, y_pred_proba):\n",
    "    thresholds = np.linspace(0.01, 0.99, 50)\n",
    "    best_f1 = 0\n",
    "    for t in thresholds:\n",
    "        y_pred_at_t = (y_pred_proba >= t).astype(int)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            current_f1 = f1_score(y_true, y_pred_at_t, zero_division=0)\n",
    "        if current_f1 > best_f1:\n",
    "            best_f1 = current_f1\n",
    "    return best_f1\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6742012-599e-4956-ae11-46d13866e97f",
   "metadata": {},
   "source": [
    "### Brain-overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cb2622-5d53-4b95-9e59-a8baa825fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Logistic Regression Model Evaluation for Tag: brain-overload\n",
      "Accuracy: 0.5403225806451613\n",
      "ROC-AUC: 0.509906948072915\n",
      "Precision: 0.47530864197530864\n",
      "Recall: 0.4723926380368098\n",
      "F1 Score: 0.4738461538461538\n"
     ]
    }
   ],
   "source": [
    "tag = 'brain-overload'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba18e78-ef25-4817-b634-9d731250ca5c",
   "metadata": {},
   "source": [
    "### Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32842938-54c2-4141-b07f-c3cfa6914962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Logistic Regression Model Evaluation for Tag: unused\n",
      "Accuracy: 0.5188172043010753\n",
      "ROC-AUC: 0.5313815023726385\n",
      "Precision: 0.4336734693877551\n",
      "Recall: 0.5555555555555556\n",
      "F1 Score: 0.4871060171919771\n"
     ]
    }
   ],
   "source": [
    "tag = 'unused'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4b5e7-c1ef-4497-bfa1-67ed9b4d9648",
   "metadata": {},
   "source": [
    "### Error-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80d0e363-2577-4969-aa80-2bbc676d5286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: error-handling\n",
      "Accuracy: 0.5080645161290323\n",
      "ROC-AUC: 0.4895314057826521\n",
      "Precision: 0.36257309941520466\n",
      "Recall: 0.45588235294117646\n",
      "F1 Score: 0.4039087947882736\n"
     ]
    }
   ],
   "source": [
    "tag = 'error-handling'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1151ee5-2c6f-4d84-8570-59ab748387b7",
   "metadata": {},
   "source": [
    "### Bad-practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3bcfc6c-f583-48e2-b468-6efea6cd90eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: bad-practice\n",
      "Accuracy: 0.5887096774193549\n",
      "ROC-AUC: 0.546389558802667\n",
      "Precision: 0.3284671532846715\n",
      "Recall: 0.42452830188679247\n",
      "F1 Score: 0.37037037037037035\n"
     ]
    }
   ],
   "source": [
    "tag = 'bad-practice'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708edaa-d08e-421e-afcf-4d28c5d63b7e",
   "metadata": {},
   "source": [
    "### Pitfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1081d4-88c2-4803-85af-874bc8a66060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: pitfall\n",
      "Accuracy: 0.5698924731182796\n",
      "ROC-AUC: 0.5613695090439276\n",
      "Precision: 0.36470588235294116\n",
      "Recall: 0.543859649122807\n",
      "F1 Score: 0.4366197183098592\n"
     ]
    }
   ],
   "source": [
    "tag = 'pitfall'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ca23b-4b54-428e-b45a-bfc1bb7efa00",
   "metadata": {},
   "source": [
    "### Clumsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7279b8e-fd39-49e9-b233-d814d8818647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Logistic Regression Model Evaluation for Tag: clumsy\n",
      "Accuracy: 0.5161290322580645\n",
      "ROC-AUC: 0.5069019447844418\n",
      "Precision: 0.2962962962962963\n",
      "Recall: 0.42105263157894735\n",
      "F1 Score: 0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "tag = 'clumsy'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd800de-676c-4fbf-a43f-b2db811cc870",
   "metadata": {},
   "source": [
    "### Suspicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218d8953-a84a-4167-9481-a57579a9be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: suspicious\n",
      "Accuracy: 0.5241935483870968\n",
      "ROC-AUC: 0.580319535221496\n",
      "Precision: 0.3271889400921659\n",
      "Recall: 0.696078431372549\n",
      "F1 Score: 0.44514106583072105\n"
     ]
    }
   ],
   "source": [
    "tag = 'suspicious'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64332c83-5799-422b-a75a-959fbbf78f9d",
   "metadata": {},
   "source": [
    "### Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5adfaff3-d6b7-45fb-8afb-d8ab6b68131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: design\n",
      "Accuracy: 0.6532258064516129\n",
      "ROC-AUC: 0.5350560516815505\n",
      "Precision: 0.3333333333333333\n",
      "Recall: 0.35789473684210527\n",
      "F1 Score: 0.3451776649746193\n"
     ]
    }
   ],
   "source": [
    "tag = 'design'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dd298-bc58-4aa6-92e7-6d6a4bdbc0fc",
   "metadata": {},
   "source": [
    "### Antipattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63f1d73-3df2-4119-80a4-c515724e2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: antipattern\n",
      "Accuracy: 0.5591397849462365\n",
      "ROC-AUC: 0.552615039281706\n",
      "Precision: 0.2236024844720497\n",
      "Recall: 0.48\n",
      "F1 Score: 0.3050847457627119\n"
     ]
    }
   ],
   "source": [
    "tag = 'antipattern'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49418790-058b-475f-9e7e-3ead61a82357",
   "metadata": {},
   "source": [
    "### Redundant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66866c54-4cb1-45ba-9d7a-edeee44b4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Logistic Regression Model Evaluation for Tag: redundant\n",
      "Accuracy: 0.5295698924731183\n",
      "ROC-AUC: 0.5988198757763975\n",
      "Precision: 0.1657754010695187\n",
      "Recall: 0.62\n",
      "F1 Score: 0.2616033755274262\n"
     ]
    }
   ],
   "source": [
    "tag = 'redundant'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c04d7-5f60-4c38-b99d-d6ad95ea6701",
   "metadata": {},
   "source": [
    "### Confusing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f344edbf-b200-436a-a5f6-ebf5ed000c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: confusing\n",
      "Accuracy: 0.4596774193548387\n",
      "ROC-AUC: 0.5972052638719305\n",
      "Precision: 0.0673076923076923\n",
      "Recall: 0.6666666666666666\n",
      "F1 Score: 0.1222707423580786\n"
     ]
    }
   ],
   "source": [
    "tag = 'confusing'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac534986-a617-4bb9-a832-adf43dba4500",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9384f53f-09bb-4871-8292-852e115c1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: performance\n",
      "Accuracy: 0.6182795698924731\n",
      "ROC-AUC: 0.5174418604651163\n",
      "Precision: 0.09285714285714286\n",
      "Recall: 0.4642857142857143\n",
      "F1 Score: 0.15476190476190477\n"
     ]
    }
   ],
   "source": [
    "tag = 'performance'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8a844-07f6-4b20-bb06-63009937f5c4",
   "metadata": {},
   "source": [
    "### Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38eb9fbf-a735-4493-9e14-80bdec777d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters: {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "Logistic Regression Model Evaluation for Tag: obsolete\n",
      "Accuracy: 0.6639784946236559\n",
      "ROC-AUC: 0.598816029143898\n",
      "Precision: 0.024\n",
      "Recall: 0.5\n",
      "F1 Score: 0.04580152671755725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carol\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tag = 'obsolete'\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
    "\n",
    "y_train_temp = y_train[tag]\n",
    "y_test_temp = y_test[tag]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # inverse of regularization strength\n",
    "    'penalty': ['l1', 'l2'], # regularization type\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# create the scorer, indicating it needs probabilities\n",
    "f1_tuned_threshold = make_scorer(custom_f1_with_threshold_tuning, needs_proba=True)\n",
    "    \n",
    "# 5-fold stratified cross validation setup (stratified k fold to balance classes in folds)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# grid search on param_grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_tuned_threshold,\n",
    "    cv=skf,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train_temp)\n",
    "\n",
    "# extract best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# predictions for test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# evaluation\n",
    "roc_auc = roc_auc_score(y_test_temp, y_pred_proba)\n",
    "acc = accuracy_score(y_test_temp, y_pred)\n",
    "prec = precision_score(y_test_temp, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test_temp, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test_temp, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Logistic Regression Model Evaluation for Tag: {tag}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# save model\n",
    "filename_joblib = os.path.join(model_save_dir, \"LogisticRegression\", f\"LogisticRegression_{tag}.joblib\")\n",
    "os.makedirs(os.path.dirname(filename_joblib), exist_ok=True)\n",
    "dump(best_model, filename_joblib)\n",
    "\n",
    "# save metrics\n",
    "roc_auc_list.append(roc_auc)\n",
    "acc_list.append(acc)\n",
    "prec_list.append(prec)\n",
    "recall_list.append(recall)\n",
    "f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4d143-ff09-49ac-9459-4e88c3078b6d",
   "metadata": {},
   "source": [
    "## Save Model Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dadbd024-07a0-4378-9130-6d2f0e3bedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = ['convention', 'brain-overload', 'unused',\n",
    "       'error-handling', 'bad-practice', 'pitfall', 'clumsy', 'suspicious',\n",
    "       'design', 'antipattern', 'redundant', 'confusing', 'performance',\n",
    "       'obsolete']\n",
    "data = {\n",
    "    'Tag': tag_list,\n",
    "    'ROC-AUC': roc_auc_list,\n",
    "    'Accuracy': acc_list,\n",
    "    'Precision': prec_list,\n",
    "    'Recall': recall_list,\n",
    "    'F1-Score': f1_list\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "df_results.to_csv(os.path.join(model_save_dir, 'LogisticRegression_Evaluation_Results.csv'), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
